global:
  # By default, scrape targets every 15 seconds.
  scrape_interval: 15s
  evaluation_interval: 15s

  #rule_files:
  # - "first.rules"
  # - "second.rules"

# Important - this must be at the root level similar to "global".
scrape_configs:
  # Scrape prometheus itself.
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: prometheus
    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s
    static_configs:
      - targets: ["localhost:9090"]

  # cadvisor - Monitor Containers - Created by Google.
  - job_name: cadvisor
    static_configs:
      - targets: ["cadvisor:8080"]

  - job_name: node_exporter
    metrics_path: "/metrics"
    static_configs:
      # Adding localhost:9090 will allow prometheus to monitor itself.
      #- targets: ["node-exporter:9100", "localhost:9090"]
      # Note: Creating a Docker network allows us to send requests from one container (Prometheus in this case) to another container (NodeExporter in this case) by only using its name as a domain. If we had not done it, we would have needed to provide the IP address of the NodeExporter container in prometheus.yaml as the target.
      - targets: ["node-exporter:9100"]
# global:
#   scrape_interval: 15s
#   evaluation_interval: 15s

# rule_files:
#   # - "first.rules"
#   # - "second.rules"

# scrape_configs:
#   - job_name: prometheus
#     static_configs:
#       - targets: ["localhost:9090"]

